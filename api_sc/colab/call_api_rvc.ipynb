{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/gamerzahatv/api_rvc_call_flask.git\n",
        "%cd /content\n",
        "!git clone -b full_stack https://github.com/gamerzahatv/api_rvc_call_flask.git\n"
      ],
      "metadata": {
        "id": "wcSua8KQIGrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wz0TvpllEef"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -P /content/api_rvc_call_flask/Server_AI_backend\n",
        "%cd /content/api_rvc_call_flask/Server_AI_backend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu==1.7.4\n",
        "!pip install ffmpeg\n",
        "!pip install fairseq==0.12.2\n",
        "!pip install praat-parselmouth==0.4.3\n",
        "!pip install torchcrepe==0.0.21\n",
        "!pip install pyworld==0.3.2\n",
        "!pip install flask_ngrok2\n",
        "!pip install Flask-Cors\n",
        "!pip install ffmpeg-python\n",
        "!pip install gdown"
      ],
      "metadata": {
        "id": "b1q-y1OVs3ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/api_rvc_call_flask/Server_AI_backend\n",
        "import base64 ,io ,csv,zipfile ,gdown ,base64,wave\n",
        "import  glob, subprocess, torch, os, traceback, sys, warnings, shutil, numpy as np\n",
        "import json, datetime, requests\n",
        "import pandas as pd\n",
        "print(os.path)\n",
        "sys.path.append('/content/api_rvc_call_flask/Server_AI_backend')\n",
        "import threading\n",
        "from time import sleep\n",
        "from subprocess import Popen\n",
        "import faiss\n",
        "from random import shuffle\n",
        "from config import Config\n",
        "from upload import upload_model\n",
        "config = Config()\n",
        "#from gtts import gTTS\n",
        "now_dir = os.getcwd()\n",
        "sys.path.append(now_dir)\n",
        "tmp = os.path.join(now_dir, \"TEMP\")\n",
        "shutil.rmtree(tmp, ignore_errors=True)\n",
        "shutil.rmtree(\"%s/runtime/Lib/site-packages/infer_pack\" % (now_dir), ignore_errors=True)\n",
        "shutil.rmtree(\"%s/runtime/Lib/site-packages/uvr5_pack\" % (now_dir), ignore_errors=True)\n",
        "os.makedirs(tmp, exist_ok=True)\n",
        "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)\n",
        "os.environ[\"TEMP\"] = tmp\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(114514)\n",
        "import ffmpeg\n",
        "ngpu = torch.cuda.device_count()\n",
        "gpu_infos = []\n",
        "mem = []\n",
        "if (not torch.cuda.is_available()) or ngpu == 0:\n",
        "    if_gpu_ok = False\n",
        "else:\n",
        "    if_gpu_ok = False\n",
        "    for i in range(ngpu):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        if (\n",
        "            \"10\" in gpu_name\n",
        "            or \"16\" in gpu_name\n",
        "            or \"20\" in gpu_name\n",
        "            or \"30\" in gpu_name\n",
        "            or \"40\" in gpu_name\n",
        "            or \"A2\" in gpu_name.upper()\n",
        "            or \"A3\" in gpu_name.upper()\n",
        "            or \"A4\" in gpu_name.upper()\n",
        "            or \"P4\" in gpu_name.upper()\n",
        "            or \"A50\" in gpu_name.upper()\n",
        "            or \"A60\" in gpu_name.upper()\n",
        "            or \"70\" in gpu_name\n",
        "            or \"80\" in gpu_name\n",
        "            or \"90\" in gpu_name\n",
        "            or \"M4\" in gpu_name.upper()\n",
        "            or \"T4\" in gpu_name.upper()\n",
        "            or \"TITAN\" in gpu_name.upper()\n",
        "        ):  # A10#A100#V100#A40#P40#M40#K80#A4500\n",
        "            if_gpu_ok = True  # 至少有一张能用的N卡\n",
        "            gpu_infos.append(\"%s\\t%s\" % (i, gpu_name))\n",
        "            mem.append(\n",
        "                int(\n",
        "                    torch.cuda.get_device_properties(i).total_memory\n",
        "                    / 1024\n",
        "                    / 1024\n",
        "                    / 1024\n",
        "                    + 0.4\n",
        "                )\n",
        "            )\n",
        "if if_gpu_ok == True and len(gpu_infos) > 0:\n",
        "    gpu_info = \"\\n\".join(gpu_infos)\n",
        "    default_batch_size = min(mem) // 2\n",
        "else:\n",
        "    gpu_info = (\"It's a pity that you don't have a working graphics card to support your training\")\n",
        "    default_batch_size = 1\n",
        "gpus = \"-\".join([i[0] for i in gpu_infos])\n",
        "#from lib.infer_pack.models import (\n",
        "from infer_pack.models import (\n",
        "    SynthesizerTrnMs256NSFsid,\n",
        "    SynthesizerTrnMs256NSFsid_nono,\n",
        "    SynthesizerTrnMs768NSFsid,\n",
        "    SynthesizerTrnMs768NSFsid_nono,\n",
        ")\n",
        "import soundfile as sf\n",
        "from fairseq import checkpoint_utils\n",
        "import logging\n",
        "from vc_infer_pipeline import VC\n",
        "from infer_uvr5 import _audio_pre_, _audio_pre_new\n",
        "from my_utils import load_audio  #Requires the ffmpeg CLI and `ffmpeg-python` package to be installed.\n",
        "\n",
        "from train.process_ckpt import show_info, change_info, merge, extract_small_model\n",
        "\n",
        "#config = Config()\n",
        "# from trainset_preprocess_pipeline import PreProcess\n",
        "logging.getLogger(\"numba\").setLevel(logging.WARNING)\n",
        "\n",
        "hubert_model = None\n",
        "def load_hubert():\n",
        "    \"\"\"Load hubert file\"\"\"\n",
        "    global hubert_model\n",
        "    models, _, _ = checkpoint_utils.load_model_ensemble_and_task(\n",
        "        [\"hubert_base.pt\"],\n",
        "        suffix=\"\",\n",
        "    )\n",
        "    hubert_model = models[0]\n",
        "    hubert_model = hubert_model.to(config.device)\n",
        "    if config.is_half:\n",
        "        hubert_model = hubert_model.half()\n",
        "    else:\n",
        "        hubert_model = hubert_model.float()\n",
        "    hubert_model.eval()\n",
        "\n",
        "#load pth and index\n",
        "weight_root = \"weights\"\n",
        "weight_uvr5_root = \"uvr5_weights\"\n",
        "index_root = \"logs\"\n",
        "names = []\n",
        "for name in os.listdir(weight_root):\n",
        "    if name.endswith(\".pth\"):\n",
        "        names.append(name)\n",
        "index_paths = []\n",
        "for root, dirs, files in os.walk(index_root, topdown=False):\n",
        "    for name in files:\n",
        "        if name.endswith(\".index\") and \"trained\" not in name:\n",
        "            index_paths.append(\"%s/%s\" % (root, name))\n",
        "uvr5_names = []\n",
        "for name in os.listdir(weight_uvr5_root):\n",
        "    if name.endswith(\".pth\") or \"onnx\" in name:\n",
        "        uvr5_names.append(name.replace(\".pth\", \"\"))\n",
        "\n",
        "\n",
        "def vc_single(\n",
        "    sid,\n",
        "    input_audio_path,\n",
        "    f0_up_key,\n",
        "    f0_file,\n",
        "    f0_method,\n",
        "    file_index,\n",
        "    #file_index2,\n",
        "    # file_big_npy,\n",
        "    index_rate,\n",
        "    filter_radius,\n",
        "    resample_sr,\n",
        "    rms_mix_rate,\n",
        "    protect,\n",
        "    crepe_hop_length,\n",
        "):  # spk_item, input_audio0, vc_transform0,f0_file,f0method0\n",
        "    global tgt_sr, net_g, vc, hubert_model, version\n",
        "    if input_audio_path is None:\n",
        "        return \"You need to upload an audio\", None\n",
        "    f0_up_key = int(f0_up_key)\n",
        "    try:\n",
        "        audio = load_audio(input_audio_path, 16000)\n",
        "        audio_max = np.abs(audio).max() / 0.95\n",
        "        if audio_max > 1:\n",
        "            audio /= audio_max\n",
        "        times = [0, 0, 0]\n",
        "        if hubert_model == None:\n",
        "            load_hubert()\n",
        "        if_f0 = cpt.get(\"f0\", 1)\n",
        "        file_index = (\n",
        "            (\n",
        "                file_index.strip(\" \")\n",
        "                .strip('\"')\n",
        "                .strip(\"\\n\")\n",
        "                .strip('\"')\n",
        "                .strip(\" \")\n",
        "                .replace(\"trained\", \"added\")\n",
        "            )\n",
        "        )  # 防止小白写错，自动帮他替换掉\n",
        "        # file_big_npy = (\n",
        "        #     file_big_npy.strip(\" \").strip('\"').strip(\"\\n\").strip('\"').strip(\" \")\n",
        "        # )\n",
        "        audio_opt = vc.pipeline(\n",
        "            hubert_model,\n",
        "            net_g,\n",
        "            sid,\n",
        "            audio,\n",
        "            input_audio_path,\n",
        "            times,\n",
        "            f0_up_key,\n",
        "            f0_method,\n",
        "            file_index,\n",
        "            # file_big_npy,\n",
        "            index_rate,\n",
        "            if_f0,\n",
        "            filter_radius,\n",
        "            tgt_sr,\n",
        "            resample_sr,\n",
        "            rms_mix_rate,\n",
        "            version,\n",
        "            protect,\n",
        "            crepe_hop_length,\n",
        "            f0_file=f0_file,\n",
        "        )\n",
        "        if resample_sr >= 16000 and tgt_sr != resample_sr:\n",
        "            tgt_sr = resample_sr\n",
        "        index_info = (\n",
        "            \"Using index:%s.\" % file_index\n",
        "            if os.path.exists(file_index)\n",
        "            else \"Index not used.\"\n",
        "        )\n",
        "        return \"Success.\\n %s\\nTime:\\n npy:%ss, f0:%ss, infer:%ss\" % (\n",
        "            index_info,\n",
        "            times[0],\n",
        "            times[1],\n",
        "            times[2],\n",
        "        ), (tgt_sr, audio_opt)\n",
        "    except:\n",
        "        info = traceback.format_exc()\n",
        "        print(info)\n",
        "        return info, (None, None)\n",
        "\n",
        "\n",
        "def vc_multi(\n",
        "    sid,\n",
        "    dir_path,\n",
        "    opt_root,\n",
        "    paths,\n",
        "    f0_up_key,\n",
        "    f0_method,\n",
        "    file_index,\n",
        "    file_index2,\n",
        "    # file_big_npy,\n",
        "    index_rate,\n",
        "    filter_radius,\n",
        "    resample_sr,\n",
        "    rms_mix_rate,\n",
        "    protect,\n",
        "    format1,\n",
        "    crepe_hop_length,\n",
        "):\n",
        "    try:\n",
        "        dir_path = (\n",
        "            dir_path.strip(\" \").strip('\"').strip(\"\\n\").strip('\"').strip(\" \")\n",
        "        )  # 防止小白拷路径头尾带了空格和\"和回车\n",
        "        opt_root = opt_root.strip(\" \").strip('\"').strip(\"\\n\").strip('\"').strip(\" \")\n",
        "        os.makedirs(opt_root, exist_ok=True)\n",
        "        try:\n",
        "            if dir_path != \"\":\n",
        "                paths = [os.path.join(dir_path, name) for name in os.listdir(dir_path)]\n",
        "            else:\n",
        "                paths = [path.name for path in paths]\n",
        "        except:\n",
        "            traceback.print_exc()\n",
        "            paths = [path.name for path in paths]\n",
        "        infos = []\n",
        "        for path in paths:\n",
        "            info, opt = vc_single(\n",
        "                sid,\n",
        "                path,\n",
        "                f0_up_key,\n",
        "                None,\n",
        "                f0_method,\n",
        "                file_index,\n",
        "                file_index2,\n",
        "                # file_big_npy,\n",
        "                index_rate,\n",
        "                filter_radius,\n",
        "                resample_sr,\n",
        "                rms_mix_rate,\n",
        "                protect,\n",
        "                crepe_hop_length\n",
        "            )\n",
        "            if \"Success\" in info:\n",
        "                try:\n",
        "                    tgt_sr, audio_opt = opt\n",
        "                    if format1 in [\"wav\", \"flac\"]:\n",
        "                        sf.write(\n",
        "                            \"%s/%s.%s\" % (opt_root, os.path.basename(path), format1),\n",
        "                            audio_opt,\n",
        "                            tgt_sr,\n",
        "                        )\n",
        "                    else:\n",
        "                        path = \"%s/%s.wav\" % (opt_root, os.path.basename(path))\n",
        "                        sf.write(\n",
        "                            path,\n",
        "                            audio_opt,\n",
        "                            tgt_sr,\n",
        "                        )\n",
        "                        if os.path.exists(path):\n",
        "                            os.system(\n",
        "                                \"ffmpeg -i %s -vn %s -q:a 2 -y\"\n",
        "                                % (path, path[:-4] + \".%s\" % format1)\n",
        "                            )\n",
        "                except:\n",
        "                    info += traceback.format_exc()\n",
        "            infos.append(\"%s->%s\" % (os.path.basename(path), info))\n",
        "            yield \"\\n\".join(infos)\n",
        "        yield \"\\n\".join(infos)\n",
        "    except:\n",
        "        yield traceback.format_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get model pth in floder weight  load all\n",
        "def get_vc(sid):\n",
        "    global n_spk, tgt_sr, net_g, vc, cpt, version\n",
        "    if sid == \"\" or sid == []:\n",
        "        global hubert_model\n",
        "        if hubert_model != None:  # 考虑到轮询, 需要加个判断看是否 sid 是由有模型切换到无模型的\n",
        "            print(\"clean_empty_cache\")\n",
        "            del net_g, n_spk, vc, hubert_model, tgt_sr  # ,cpt\n",
        "            hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            ###楼下不这么折腾清理不干净\n",
        "            if_f0 = cpt.get(\"f0\", 1)\n",
        "            version = cpt.get(\"version\", \"v1\")\n",
        "            if version == \"v1\":\n",
        "                if if_f0 == 1:\n",
        "                    net_g = SynthesizerTrnMs256NSFsid(\n",
        "                        *cpt[\"config\"], is_half=config.is_half\n",
        "                    )\n",
        "                else:\n",
        "                    net_g = SynthesizerTrnMs256NSFsid_nono(*cpt[\"config\"])\n",
        "            elif version == \"v2\":\n",
        "                if if_f0 == 1:\n",
        "                    net_g = SynthesizerTrnMs768NSFsid(\n",
        "                        *cpt[\"config\"], is_half=config.is_half\n",
        "                    )\n",
        "                else:\n",
        "                    net_g = SynthesizerTrnMs768NSFsid_nono(*cpt[\"config\"])\n",
        "            del net_g, cpt\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            cpt = None\n",
        "        return {\"visible\": False, \"__type__\": \"update\"}\n",
        "    person = \"%s/%s\" % (weight_root, sid)\n",
        "    print(\"loading %s\" % person)   #load model select\n",
        "    cpt = torch.load(person, map_location=\"cpu\")\n",
        "    tgt_sr = cpt[\"config\"][-1]\n",
        "    cpt[\"config\"][-3] = cpt[\"weight\"][\"emb_g.weight\"].shape[0]  # n_spk\n",
        "    if_f0 = cpt.get(\"f0\", 1)\n",
        "    version = cpt.get(\"version\", \"v1\")\n",
        "    if version == \"v1\":\n",
        "        if if_f0 == 1:\n",
        "             net_g = SynthesizerTrnMs256NSFsid(*cpt[\"config\"], is_half=config.is_half)\n",
        "        else:\n",
        "             net_g = SynthesizerTrnMs256NSFsid_nono(*cpt[\"config\"])\n",
        "    elif version == \"v2\":\n",
        "         if if_f0 == 1:\n",
        "             net_g = SynthesizerTrnMs768NSFsid(*cpt[\"config\"], is_half=config.is_half)\n",
        "         else:\n",
        "             net_g = SynthesizerTrnMs768NSFsid_nono(*cpt[\"config\"])\n",
        "    del net_g.enc_q\n",
        "    print(net_g.load_state_dict(cpt[\"weight\"], strict=False))\n",
        "    print('699999999999999999999999999999999999999999999999999999999999999')\n",
        "    net_g.eval().to(config.device)\n",
        "    if config.is_half:\n",
        "        net_g = net_g.half()\n",
        "    else:\n",
        "        net_g = net_g.float()\n",
        "    vc = VC(tgt_sr, config)\n",
        "    n_spk = cpt[\"config\"][-3]\n",
        "    return {\"visible\": False, \"maximum\": n_spk, \"__type__\": \"update\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean():\n",
        "    return {\"value\": \"\", \"__type__\": \"update\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re as regex\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "#cli_current_page = \"HOME\"\n",
        "\n",
        "def cli_split_command(com):\n",
        "    print(\"MONGKOL NAMAWRONG\")\n",
        "    exp = r'(?:(?<=\\s)|^)\"(.*?)\"(?=\\s|$)|(\\S+)'\n",
        "    split_array = regex.findall(exp, com)\n",
        "    split_array = [group[0] if group[0] else group[1] for group in split_array]\n",
        "    return split_array\n",
        "\n",
        "def execute_generator_function(genObject):\n",
        "    for _ in genObject: pass\n",
        "\n",
        "def cli_infer(com):\n",
        "    # get VC first\n",
        "    com = cli_split_command(com)\n",
        "    model_name = com[0]\n",
        "    source_audio_path = com[1]\n",
        "    output_file_name = com[2]\n",
        "    feature_index_path = com[3]\n",
        "    f0_file = None # Not Implemented Yet\n",
        "\n",
        "    # Get parameters for inference\n",
        "    speaker_id = int(com[4])\n",
        "    transposition = float(com[5])\n",
        "    f0_method = com[6]\n",
        "    crepe_hop_length = int(com[7])\n",
        "    harvest_median_filter = int(com[8])\n",
        "    resample = int(com[9])\n",
        "    mix = float(com[10])\n",
        "    feature_ratio = float(com[11])\n",
        "    protection_amnt = float(com[12])\n",
        "\n",
        "    print(\"Mangio-RVC-Fork Infer-CLI: Starting the inference...\")\n",
        "    vc_data = get_vc(model_name)\n",
        "    print(vc_data)\n",
        "    print(\"Mangio-RVC-Fork Infer-CLI: Performing inference...\")\n",
        "    conversion_data = vc_single(\n",
        "        speaker_id,\n",
        "        source_audio_path,\n",
        "        transposition,\n",
        "        f0_file,\n",
        "        f0_method,\n",
        "        feature_index_path,\n",
        "        #feature_index_path,\n",
        "        feature_ratio,\n",
        "        harvest_median_filter,\n",
        "        resample,\n",
        "        mix,\n",
        "        protection_amnt,\n",
        "        crepe_hop_length,\n",
        "    )\n",
        "    if \"Success.\" in conversion_data[0]:\n",
        "        print(\"Mangio-RVC-Fork Infer-CLI: Inference succeeded. Writing to %s/%s...\" % ('audio-outputs', output_file_name))\n",
        "        wavfile.write('%s/%s' % ('audio-outputs', output_file_name), conversion_data[1][0], conversion_data[1][1])\n",
        "        #print(\"Mangio-RVC-Fork Infer-CLI: Finished! Saved output to %s/%s\" % ('audio-outputs', output_file_name))\n",
        "        return \"Mangio-RVC-Fork Infer-CLI: Finished! Saved output to %s/%s\" % ('audio-outputs', output_file_name)\n",
        "    else:\n",
        "        print(\"Mangio-RVC-Fork Infer-CLI: Inference failed. Here's the traceback: \")\n",
        "        print(conversion_data[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_presets():\n",
        "    data = None\n",
        "    with open('../inference-presets.json', 'r') as file:\n",
        "        data = json.load(file)\n",
        "    preset_names = []\n",
        "    for preset in data['presets']:\n",
        "        preset_names.append(preset['name'])\n",
        "\n",
        "    return preset_names\n",
        "\n",
        "def change_choices2():\n",
        "    audio_files=[]\n",
        "    for filename in os.listdir(\"./audios\"):\n",
        "        if filename.endswith(('.wav','.mp3')):\n",
        "            audio_files.append(os.path.join('./audios',filename))\n",
        "    return {\"choices\": sorted(audio_files), \"__type__\": \"update\"}, {\"__type__\": \"update\"}\n",
        "\n",
        "audio_files=[]\n",
        "for filename in os.listdir(\"./audios\"):\n",
        "    if filename.endswith(('.wav','.mp3')):\n",
        "        audio_files.append(os.path.join('./audios',filename))\n",
        "\n",
        "def get_index():\n",
        "    if check_for_name() != '':\n",
        "        chosen_model=sorted(names)[0].split(\".\")[0]\n",
        "        logs_path=\"./logs/\"+chosen_model\n",
        "        if os.path.exists(logs_path):\n",
        "            for file in os.listdir(logs_path):\n",
        "                if file.endswith(\".index\"):\n",
        "                    return os.path.join(logs_path, file)\n",
        "            return ''\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "def get_indexes():\n",
        "    indexes_list=[]\n",
        "    for dirpath, dirnames, filenames in os.walk(\"./logs/\"):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(\".index\"):\n",
        "                indexes_list.append(os.path.join(dirpath,filename))\n",
        "    if len(indexes_list) > 0:\n",
        "        return indexes_list\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def get_name():\n",
        "    if len(audio_files) > 0:\n",
        "        return sorted(audio_files)[0]\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "\n",
        "\n",
        "def save_to_wav2(dropbox):\n",
        "    file_path=dropbox.name\n",
        "    shutil.move(file_path,'./audios')\n",
        "    return os.path.join('./audios',os.path.basename(file_path))\n",
        "\n",
        "def match_index(sid0):\n",
        "    folder=sid0.split(\".\")[0]\n",
        "    parent_dir=\"./logs/\"+folder\n",
        "    if os.path.exists(parent_dir):\n",
        "        for filename in os.listdir(parent_dir):\n",
        "            if filename.endswith(\".index\"):\n",
        "                index_path=os.path.join(parent_dir,filename)\n",
        "                return index_path\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def check_for_name():\n",
        "    if len(names) > 0:\n",
        "        return sorted(names)[0]\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "from flask import Flask,jsonify,request\n",
        "from flask_ngrok2 import run_with_ngrok\n",
        "import subprocess\n",
        "from flask_cors import CORS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "cors = CORS(app)\n",
        "'''Token ngrok '''\n",
        "run_with_ngrok(app=app, auth_token=\"2TzDxTPxT4PsN12y1dTd4RAjz1A_4QQQ9bAUrJ1uS6kmmKnJ4\")\n",
        "\n",
        "##################### MODULE #####################################\n",
        "'''This is module for chat '''\n",
        "\n",
        "def process_chat(getinstruction,getinput,getmodel_name):\n",
        "  try :\n",
        "    print('chat processing')\n",
        "\n",
        "    return 'Error'\n",
        "  except Exception as e:\n",
        "    return  {\"Error\": e}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.route(\"/test\", methods=[\"POST\"])\n",
        "def test():\n",
        "  try:\n",
        "\n",
        "      content_type = request.headers.get('Content-Type')\n",
        "      if (content_type == 'application/json'):\n",
        "        print('yes')\n",
        "        json = request.json\n",
        "        print(json)\n",
        "\n",
        "        if (json):\n",
        "          result = process_chat(json['instruction'], json['input'],json['model'])\n",
        "          return {'output': result }\n",
        "        else:\n",
        "          return {'output': 'Error' }\n",
        "  except Exception as e:\n",
        "      print(e)\n",
        "      return {\n",
        "        \"Error\": e,\n",
        "      }\n",
        "\n",
        "@app.route(\"/nani\", methods=[\"GET\"])\n",
        "def nani():\n",
        "  try:\n",
        "\n",
        "    content_type = request.headers.get('Content-Type')\n",
        "    sample_commands = \"serana700_e200_s7200.pth output_audio.wav feature_index_path 1 0.5 f0_method 256 5 44100 0.8 1.0 0.2\"\n",
        "    sample_command = '\"serana/serana.pth\" \"./audios/someguy.mp3\" \"output_audio.wav\" \"./logs/serana/serana.index\" 0 12 \"pm\" 120 5  5 0.0  0.0 0.0'\n",
        "\n",
        "    nani = cli_infer(sample_command)\n",
        "    return {'output':  nani  }\n",
        "  except Exception as e:\n",
        "      print(e)\n",
        "      return {\n",
        "        \"Error\": e,\n",
        "      }\n",
        "\n",
        "# send voic image\n",
        "def prompt_text():\n",
        "  print('inputhere')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def image_path():\n",
        "  getimage_dir = os.path.join(os.getcwd(),'voice_model_image','serana','serana.png')\n",
        "  get_index = os.path.join(os.getcwd(),'logs','serana700_e200_s7200','serana700_v2.index')\n",
        "  get_weights = os.path.join(os.getcwd(),'weights','serana700_e200_s7200.pth')\n",
        "  print(getimage_dir)\n",
        "  print(get_index )\n",
        "  print(get_weights)\n",
        "  #print(getimage_dir)\n",
        "  with open(getimage_dir, \"rb\") as image_file:\n",
        "    image_data = image_file.read()\n",
        "    image_blob = base64.b64encode(image_data).decode('utf-8')\n",
        "  return image_blob\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#upload model\n",
        "@app.route(\"/uploadmodel\", methods=[\"POST\"])\n",
        "def uploadmodel():\n",
        "\n",
        "  try:\n",
        "    print('loadmodel')\n",
        "    content_type = request.headers.get('Content-Type')\n",
        "    if (content_type == 'application/json'):\n",
        "      print('yes')\n",
        "      json_data = request.get_json()\n",
        "      get_url = json_data.get('url')\n",
        "      get_modelname =  json_data.get('namemodel')\n",
        "\n",
        "      if (json):\n",
        "        try:\n",
        "          upload_model(get_modelname,get_url)\n",
        "          return  {\n",
        "          'output':'uploadmodel Succes',\n",
        "          }\n",
        "        except:\n",
        "          return {\n",
        "          'output':'uploadmodel error',\n",
        "          }\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return {\n",
        "      \"Error\": e,\n",
        "    }\n",
        "\n",
        "#upload audio\n",
        "@app.route(\"/uploadaudio\", methods=[\"POST\"])\n",
        "def uploadaudio():\n",
        "\n",
        "  try:\n",
        "    print('uploadaudio')\n",
        "    content_type = request.headers.get('Content-Type')\n",
        "    if (content_type == 'application/json'):\n",
        "      print('yes')\n",
        "      json_data = request.get_json()\n",
        "      get_base64 = json_data.get('audiobase64')\n",
        "      get_audioname = json_data.get('audioname')\n",
        "\n",
        "      if (json):\n",
        "        #upload_model(get_modelname,get_url)\n",
        "        print('down ok')\n",
        "        print(get_base64)\n",
        "\n",
        "        path_audio = os.path.join('audios',get_audioname)\n",
        "\n",
        "        wav_file = open(path_audio, \"wb\")\n",
        "        decode_string = base64.b64decode(get_base64)\n",
        "        wav_file.write(decode_string)\n",
        "\n",
        "        print(\"WAV file saved:\", path_audio)\n",
        "        return {\n",
        "          'output':get_base64,\n",
        "        }\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return {\n",
        "      \"Error\": e,\n",
        "    }\n",
        "#image_path()\n",
        "@app.route(\"/sendvoicemodel\", methods=[\"POST\"])\n",
        "def send_voice_model():\n",
        "  try:\n",
        "      content_type = request.headers.get('Content-Type')\n",
        "      if (content_type == 'application/json'):\n",
        "        print('yes')\n",
        "        json_data = request.get_json()\n",
        "        print(json_data.get('name'))\n",
        "\n",
        "        if (json):\n",
        "\n",
        "          return {\n",
        "            'voice_model':json_data.get('name'),\n",
        "            'imageblob': image_path(),\n",
        "            'imagedesc': 'เป็นตัวละครที่อยู้ในเกม The Elder Scrolls V: Skyrim ใน DLC DAWNGUARD',\n",
        "            'weight':'weights',\n",
        "            'index':'index'\n",
        "          }\n",
        "        else:\n",
        "          return {'output': 'Error' }\n",
        "  except Exception as e:\n",
        "      print(e)\n",
        "      return {\n",
        "        \"Error\": e,\n",
        "      }\n",
        "\n",
        "# refresh audio\n",
        "@app.route(\"/refreshaudio\", methods=[\"GET\"])\n",
        "def refreshaudio():\n",
        "  try:\n",
        "\n",
        "    list_audio = os.path.join('audios')\n",
        "\n",
        "    wav_mp3_files = [file for file in os.listdir(list_audio) if file.endswith(('.wav', '.mp3'))]\n",
        "\n",
        "    # for file in wav_mp3_files:\n",
        "    #   print(file)\n",
        "\n",
        "    convert_json = {'output':wav_mp3_files,}\n",
        "    print(convert_json)\n",
        "    return  convert_json\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return {\n",
        "      \"Error\": e,\n",
        "    }\n",
        "\n",
        "def get_datacsv():\n",
        "  path_db = os.path.join('model_download','DB.csv')\n",
        "  df = pd.read_csv(path_db)\n",
        "  print(df.to_string())\n",
        "  # Assuming 'model' is the column name and 'serana' is the row name\n",
        "  # You can use the loc function to access the specific value\n",
        "  value = df.loc[df['columnname'] == 'serana', 'modelname'].values[0]\n",
        "  # 'value' will now contain the value from the 'model' column where 'serana' is in the specified column\n",
        "  print(value)\n",
        "\n",
        "# refresh model and audio  get in csv file\n",
        "@app.route(\"/refrehconvert\", methods=[\"GET\"])\n",
        "def refreshconvert():\n",
        "  try:\n",
        "    if os.path.exists(os.path.join('model_download','DB.csv')):\n",
        "      print('HAVE MODEL CSV')\n",
        "      get_datacsv()\n",
        "    else:\n",
        "      with open(os.path.join('model_download','DB.csv'), 'w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['modelname', 'pth_path', 'index_path'])  # Writing headers if the file is created\n",
        "        print('Create DB MODEL SUCESS')\n",
        "        get_datacsv()\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return {\n",
        "      \"Error\": e,\n",
        "    }\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "id": "ADTlKI-WmO8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7crsTr5i_3e",
        "outputId": "3dcbc7e4-94f3-45f9-c170-720bcf770a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            ">>> ^C\n"
          ]
        }
      ]
    }
  ]
}